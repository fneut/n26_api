{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = sys.path[3]\n",
    "with open(f\"{PATH}/data_to_work_account_info.json\") as f:\n",
    "    account_data = json.load(f)\n",
    "FIRST_NAME = account_data[\"kycFirstName\"].lower()\n",
    "SURNAME = account_data[\"kycLastName\"].split()[0].lower()\n",
    "SECOND_SURNAME = account_data[\"kycLastName\"].split()[-1].lower()\n",
    "FULL_NAME_LONG = f\"{FIRST_NAME} {SURNAME} {SECOND_SURNAME}\"\n",
    "FULL_NAME_SHORT = f\"{FIRST_NAME} {SURNAME}\"\n",
    "FULL_NAME_LONG, FULL_NAME_SHORT\n",
    "WORDS = stopwords.words('english') #typical words, as 'me', 'we', 'our', 'be', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def label_transaction(transactions: dict):\n",
    "    for counter, transaction_operation in enumerate(transactions):\n",
    "        if \"amount\" in transaction_operation.keys():\n",
    "            if transaction_operation[\"amount\"] > 0:\n",
    "                transactions[counter][\"expense_type\"] = \"deposit\"\n",
    "            else:\n",
    "                transactions[counter][\"expense_type\"] = \"expense\"\n",
    "    return transactions\n",
    "\n",
    "def remove_wording_in_transaction_label(transactions: dict):\n",
    "    for counter, transaction_operation in enumerate(transactions):\n",
    "        if \"category\" in transaction_operation.keys():\n",
    "            transactions[counter][\"category_preprocessed\"] = \" \".join(transaction_operation[\"category\"].split(\"micro-v2-\")[-1].split(\"-\"))\n",
    "    return transactions\n",
    "\n",
    "\n",
    "def remove_commonly_used_words_and_chars(transactions: dict, col_names: list):\n",
    "    \"\"\"\n",
    "    #keeps the descriptions of the banking transaction, and removes garbage data from the transaction string \n",
    "    # like colon, words that don't give any value as a feature. \n",
    "    # [^a-zA-Z_] match everything that is NOT an uppercase or lowercase letter at the start of the word\n",
    "    # i.e. \"-netto\" will be replaced by \" netto\"  \n",
    "    \"\"\"\n",
    "    for counter, transaction_operation in enumerate(transactions):\n",
    "        text_merged = \"\"\n",
    "        for col_name in col_names: \n",
    "            if col_name in transaction_operation.keys():\n",
    "                text_preprocessed = \" \".join([i for i in re.sub(\"[^a-zA-Z]\",\" \",transaction_operation[col_name]).split() if (i.lower() not in WORDS)]).lower()\n",
    "                transactions[counter][f\"{col_name}_preprocessed\"] = text_preprocessed\n",
    "                if (FULL_NAME_LONG not in text_preprocessed) and (FULL_NAME_SHORT not in text_preprocessed):\n",
    "                    text_merged += f\"{text_preprocessed} \"\n",
    "        if (text_merged == '') and (transaction_operation[\"paymentScheme\"] == \"SEPA\"):\n",
    "            text_merged = \"transfer\"\n",
    "        transactions[counter][\"transaction_description_merged\"] = text_merged.strip()\n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{PATH}/data_to_work_transactions.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_commonly_used_words_and_chars(data,[\"partnerName\",\"merchantName\", \"referenceText\"])\n",
    "remove_wording_in_transaction_label(data)\n",
    "label_transaction(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "    \"amount\",\n",
    "    \"merchantCity\",\n",
    "    \"merchantName\",\n",
    "    \"merchantName_preprocessed\",\n",
    "    \"category\",\n",
    "    \"category_preprocessed\",\n",
    "    \"expense_type\",\n",
    "    \"referenceText\",\n",
    "    \"referenceText_preprocessed\",\n",
    "    \"transaction_description_merged\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_csv(f\"{PATH}/training_set.csv\")\n",
    "df_training['description_preprocessed'] = df_training['description'].apply(lambda x: \" \".join([i for i in re.sub(\"[^a-zA-Z]\",\" \",x).split() if (i not in WORDS and len(i)>1)]).lower()) \n",
    "# remove_commonly_used_words_from_transactions(df_training.to_dict(\"records\"), [\"description\"])\n",
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer() #create the object\n",
    "vectorizer.fit(df_training['description']) #Gives to each word a number. Each word is a feature, givin 113 features\n",
    "X_counts_train = vectorizer.fit_transform(df_training['description']).toarray() #for each transaction, it assigns a +1 to each word in the position it was assigned. En cada transacción/fila, le asigna un \"1\" a una palabra en determinada posición, de las 113 palabras (features) que existen.\n",
    "\n",
    "######################################### ASIGN LABELS TO CATEGORIES OF THE TRAINING & TESTING SET #########################################\n",
    "\n",
    "le = preprocessing.LabelEncoder() #Encode target labels with value between 0 and n_classes-1\n",
    "Y_train = le.fit_transform(df_training['label']) #assings a label to each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_counts_train\n",
    "gnb = GaussianNB() #Naive Bayes classifier\n",
    "gnb.fit(X_train,Y_train) # Fit Gaussian Naive Bayes according to X_train and the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_counts_test = vectorizer.transform(df['transaction_description_merged']).toarray() #repeat the process of transforming each word to a number or index in an array\n",
    "Y_predicted= gnb.predict(X_counts_test) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [] \n",
    "predictions_label = [] \n",
    "for counter,x in enumerate(Y_predicted):\n",
    "    predictions.append(list(le.classes_)[x])\n",
    "    predictions_label.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(category_model = predictions, label = predictions_label)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "    \"amount\",\n",
    "    \"merchantCity\",\n",
    "    \"merchantName\",\n",
    "    \"merchantName_preprocessed\",\n",
    "    \"category\",\n",
    "    \"partnerName\",\n",
    "    \"category_preprocessed\",\n",
    "    \"expense_type\",\n",
    "    \"referenceText\",\n",
    "    \"referenceText_preprocessed\",\n",
    "    \"transaction_description_merged\",\n",
    "    \"category_model\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(f\"{PATH}/df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in df.columns:\n",
    "    print(col_name, \"\\n\", df[col_name].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"transaction_description_merged\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://stackoverflow.com/questions/15078519/python-dictionary-passed-as-an-input-to-a-function-acts-like-a-global-in-that-fu\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('n26_complete')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbd52c071d72a0da18b0e8ee20cee1d52cf062fb47881cb0131549200748fa95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
